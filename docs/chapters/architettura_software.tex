% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../main.tex

\chapter{Architettura del software}

\section{Rete lazy}\index{Rete lazy}

\section{Rete eager}\index{Rete eager}

Si riporta di seguito la struttura della cartella \texttt{networks\_eager/}.

\begin{folder}[Struttura della cartella]
	\mbox{}\\
	\dirtree{%
		.1 networks\_eager/.
		.2 experiments/.
		.3 best\_weights/.
		.3 train.log.
		.2 dataset.py.
		.2 model.py.
		.2 train.py.
		.2 params.json\DTcomment{file di configurazione dei parametri della rete}.
	}
\end{folder}

\subsection{Dataset}

Nel file \texttt{dataset.py} è definita la classe \texttt{Dataset}, la quale contiene metodi per: 
\begin{itemize}
	\item leggere l'intero dataset di immagini da file system, trasformando ogni immagine in un tensore;
	\item effettuare operazioni di preprocessing su ogni signola immagine (e.g. rescale, crop, aggiustamenti del livello di saturazione o luminosità, ecc);
	\item costruire gli oggetti \texttt{tf.data.Dataset} che consentono di ottenere batch di immagini (come tensori).
\end{itemize}
Il dataset di immagini viene suddiviso in validation set, training set e test set con le proporzioni specificate nel file \texttt{param.json} e ciascuno di questi insiemi è ottenibile chiamando gli appositi getter della classe dataset. Tali metodi restituiscono un oggetto di tipo \texttt{tf.data.Dataset} che fornisce batch di immagini di dimensione specificata nel file json di configurazione. I getter si occupano anche di aggiungere all'oggetto contenente i parametri i tre campi \texttt{validation\_size}, \texttt{training\_size} e \texttt{test\_size} che indicano il numero di immagini presenti nei relativi set. Questi parametri sono necessari per indicare alla rete quante iterazioni effettuare per ogni epoch.\\
Le operazioni di preprocessing includono il ridimensionamento delle immagini in input a immagini quadrate di dimensione specificata nel file di configurazione.\\

Per produrre i dataset da utilizzare con il modello, le funzioni getter applicano una serie di metodi sugli oggetti \texttt{tf.data.Dataset} fra cui \texttt{repeat()}. Questa operazione rende il dataset ripetibile un numero potenzialmente infinito di volte. Ad ogni epoch quindi, la funzione di training riceverà in input tutti i batch di immagini fino ad esaurire il dataset. All'epoch successiva la funzione \texttt{repeat()} consente la ripetizione dell'intero dataset che altrimenti sarebbe considerato esaurito, avendo consumato tutti i batch. Nella documentazione ufficiale di tensorflow viene infatti specificato che ogni ripetizione del dataset ottenuta dalla funzione \texttt{repeat()} è generalemente chiamata epoch\cite{repeatshuffle}.\\
Si noti inoltre che alla funzione \texttt{shuffle()} può essere passato un parametro che consente di ottenere rimescolamenti differenti del dataset ad ogni ripetizione (epoch).

\subsection{Model}

La classe \texttt{Model}, definita nel file \texttt{model.py}, espone invece i metodi per avviare il training della rete e per la sua valutazione. Il costruttore prende in input degli 3 oggetti di tipo \texttt{tf.data.Dataset} (training, validation e test set).\\ L'architettura della rete è definita dal metodo \texttt{\_build()} che costruisce i vari strati utilizzando il modello sequenziale di \gls{Keras}. Per cambiare l'architettura quindi va modificato il suddetto metodo.\\

Il metodo \texttt{train()} si occupa di ripristinare i pesi dalla migliore iterazione precedente (che sono salvati nella cartella \texttt{experiments/best\_weighs/}) nel caso il parametro nel file di configurazione lo richieda e sia presente un salvataggio. Riguardo a questa funzionalità bisogna gestire il caso in cui l'architettura della rete o alcuni parametri siano stati modificati e i pesi non siano più utilizzabili perché specifici per una rete diversa. In tal caso sarebbe il caso di \red{segnalare il problema con un messaggio nel log} e procedere a ri-effettuare il training ignorando il vecchio file dei pesi. Si aggiunge inoltre che attualmente è impossibile salvare - e di conseguenza salvare - lo stato dell'ottimizzatore in quanto impossibile nella versione di \texttt{tf.keras==1.13.1}. Questo problema è stato risolto nella versione 2.0 di TF\\
Il salvataggio dei pesi avviene dopo ogni epoch e viene effettuato creando un oggetto \texttt{Model\-Checkpoint} (definito nella libreria Keras) il quale dovrebbe sovrascrivere i pesi ad ogni epoch se la funzione target (loss o accuracy) è diminuita/aumentata, a seconda dei parametri passati nel costruttore del checkpoint. \red{Va capito perché tale metodo non sembra funzionare se esiste già un file nella cartella}. Il metodo \texttt{train()} chiama poi il metodo \texttt{model.fit()} che esegue il training. Fra i parametri va indicato il numero di step per epoch, che significa il numero di batch da processare in una epoch (dato dalla dimensione del dataset divisa per la dimensione di un batch).\\
Alla funzione \texttt{fit()} viene fornito anche il validation set al parametro \texttt{validation\_data}. Questo permette alla funzione di effettuare un passaggio di valutazione dopo ogni epoch e calcolare le metriche anche rispetto al validation set. Tale passaggio è utile per monitorare che il miglioramento avvenga rispetto al validation set più che rispetto al training set.
I risultati della fase di training possono poi essere visualizzati su \red{tensorboard}.\\

Il metodo \texttt{evaluate()} è utile per valutare le performance di un modello allenato su uno specifico dataset, del quale è necessario indicare anche la dimensione (per poter indicare il numero di passi per epoch). \red{Il metodo dovrebbe ritornare \textit{n} scalari che rappresentano la valutazione delle \textit{n} metriche sul dataset}.\\

Il metodo \texttt{predict()} ritorna l'array di predizioni effettuate dal modello allenato sul test set fornito al costruttore dell'oggetto \texttt{Model}. \blue{Alternativamente} si potrebbe usare un metodo \texttt{predict\_classes()} di Keras, che invece che ritornare le probabilità di appartenenza a ciascuna classe ritorna direttamente la classe più probabile.

\subsection{Altri file}

Dal file \texttt{train.py} è possibile avviare il training della rete. Corrisponde quindi al file \textit{main}. Esso avvia la lettura del file con i parametri, istanzia l'oggetto \texttt{Dataset}, avvia lo split in training/validation/test set e fornisce questi insiemi al costruttore di \texttt{Model} dal quale è possibile avviare l'allenamento della rete.\\

Nel file \texttt{utils.py} sono definiti dei metodi di utilità, quali il logger e una classe \texttt{Params} per leggere e aggiornare il file \textit{json} con i parametri.

